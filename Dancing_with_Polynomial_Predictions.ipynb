{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjYmXoneK6cS9UWoKWjsLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Hossein-Hosseini/Dancing_with_Polynomial_Predictions/blob/master/Dancing_with_Polynomial_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dancing with Polynomial Predictions**"
      ],
      "metadata": {
        "id": "ON23E6jOj3qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "2k4-7PjhkKx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MFMQ6GgrjoDU"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Description**"
      ],
      "metadata": {
        "id": "Es8IK7CXkVWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_path = 'Polynomial_Functions.xlsx'  # Change the path if needed\n",
        "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "\n",
        "# Display general information about the dataset\n",
        "print(\"ðŸ”¹ Dataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values in each column\n",
        "print(\"\\nðŸ”¹ Missing Values Per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Show descriptive statistics\n",
        "print(\"\\nðŸ”¹ Descriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Count unique values in each column\n",
        "print(\"\\nðŸ”¹ Number of Unique Values Per Column:\")\n",
        "print(df.nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiVCh7TYkckA",
        "outputId": "bc3a12b0-4575-413c-b5f5-e5f0efe2d542"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   x           10000 non-null  float64\n",
            " 1   y           10000 non-null  float64\n",
            " 2   z           10000 non-null  float64\n",
            " 3   F(x, y, z)  10000 non-null  float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 312.6 KB\n",
            "None\n",
            "\n",
            "ðŸ”¹ Missing Values Per Column:\n",
            "x             0\n",
            "y             0\n",
            "z             0\n",
            "F(x, y, z)    0\n",
            "dtype: int64\n",
            "\n",
            "ðŸ”¹ Descriptive Statistics:\n",
            "                  x             y             z    F(x, y, z)\n",
            "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
            "mean      -0.116809      0.090598      0.001008     43.803057\n",
            "std        5.752603      5.785891      5.735475    587.941231\n",
            "min       -9.999767     -9.996845     -9.999038  -3191.680304\n",
            "25%       -5.073423     -4.921084     -4.925042   -225.322605\n",
            "50%       -0.149428      0.117936      0.041362     15.622764\n",
            "75%        4.800127      5.129584      4.893477    301.709432\n",
            "max        9.994353      9.998497      9.998020   3508.399526\n",
            "\n",
            "ðŸ”¹ Number of Unique Values Per Column:\n",
            "x             10000\n",
            "y             10000\n",
            "z             10000\n",
            "F(x, y, z)    10000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train/Test Split**"
      ],
      "metadata": {
        "id": "nFjcyGAF2WzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop('F(x, y, z)', axis=1)\n",
        "y = df['F(x, y, z)']\n",
        "\n",
        "# Split into training and test sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the sizes\n",
        "print(f\"Training set size: {X_train.shape[0]} rows\")\n",
        "print(f\"Test set size: {X_test.shape[0]} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQOELNok2n80",
        "outputId": "c2bff4d6-7156-4133-9f95-e3d5457b3705"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 8000 rows\n",
            "Test set size: 2000 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "tWgTmnBI14-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove Outliers**"
      ],
      "metadata": {
        "id": "OfAJ7e9el09S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_auto_xy_with_output(x, y):\n",
        "    \"\"\"\n",
        "    Automatically detect and remove outliers from the training data (x, y) using the IQR method.\n",
        "    Removes rows from both x and y simultaneously when an outlier is detected in either x or y.\n",
        "\n",
        "    Parameters:\n",
        "        x (pd.DataFrame): Input feature DataFrame (training data)\n",
        "        y (pd.Series): Input target Series (labels)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame, pd.Series: Cleaned feature DataFrame and target Series with outliers removed\n",
        "    \"\"\"\n",
        "    initial_shape = x.shape\n",
        "    print(f\"ðŸ”¹ Initial dataset size: {initial_shape[0]} rows, {initial_shape[1]} columns (x), {y.shape[0]} rows (y)\\n\")\n",
        "\n",
        "    # For numeric columns in x\n",
        "    numeric_cols_x = x.select_dtypes(include='number').columns\n",
        "    x_clean = x.copy()\n",
        "    y_clean = y.copy()\n",
        "\n",
        "    # Remove outliers from x\n",
        "    for col in numeric_cols_x:\n",
        "        Q1 = x[col].quantile(0.25)\n",
        "        Q3 = x[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        before = x_clean.shape[0]\n",
        "        mask = (x_clean[col] >= lower_bound) & (x_clean[col] <= upper_bound)\n",
        "\n",
        "        # Apply the same mask to both x and y\n",
        "        x_clean = x_clean[mask]\n",
        "        y_clean = y_clean[mask]\n",
        "\n",
        "        after = x_clean.shape[0]\n",
        "        removed = before - after\n",
        "\n",
        "        if removed > 0:\n",
        "            print(f\"ðŸŸ  Removed {removed} outliers from column '{col}' in x\")\n",
        "        else:\n",
        "            print(f\"âœ… No outliers detected in column '{col}' in x\")\n",
        "\n",
        "    # For the target variable y\n",
        "    Q1_y = y_clean.quantile(0.25)\n",
        "    Q3_y = y_clean.quantile(0.75)\n",
        "    IQR_y = Q3_y - Q1_y\n",
        "    lower_bound_y = Q1_y - 1.5 * IQR_y\n",
        "    upper_bound_y = Q3_y + 1.5 * IQR_y\n",
        "\n",
        "    before_y = y_clean.shape[0]\n",
        "    y_mask = (y_clean >= lower_bound_y) & (y_clean <= upper_bound_y)\n",
        "\n",
        "    # Apply the same mask to both x and y\n",
        "    x_clean = x_clean[y_mask]\n",
        "    y_clean = y_clean[y_mask]\n",
        "\n",
        "    after_y = x_clean.shape[0]\n",
        "    removed_y = before_y - after_y\n",
        "\n",
        "    if removed_y > 0:\n",
        "        print(f\"ðŸŸ  Removed {removed_y} outliers from target variable y\")\n",
        "    else:\n",
        "        print(f\"âœ… No outliers detected in target variable y\")\n",
        "\n",
        "    print(f\"\\nâœ… Final dataset size: {x_clean.shape[0]} rows (removed {initial_shape[0] - x_clean.shape[0]} total rows)\")\n",
        "    return x_clean, y_clean\n",
        "\n",
        "# Example usage:\n",
        "X_train_clean, y_train_clean = remove_outliers_auto_xy_with_output(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnyNSg5nl1S9",
        "outputId": "e0f885ef-0497-4115-abb0-a7613da14bb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Initial dataset size: 8000 rows, 3 columns (x), 8000 rows (y)\n",
            "\n",
            "âœ… No outliers detected in column 'x' in x\n",
            "âœ… No outliers detected in column 'y' in x\n",
            "âœ… No outliers detected in column 'z' in x\n",
            "ðŸŸ  Removed 603 outliers from target variable y\n",
            "\n",
            "âœ… Final dataset size: 7397 rows (removed 603 total rows)\n"
          ]
        }
      ]
    }
  ]
}