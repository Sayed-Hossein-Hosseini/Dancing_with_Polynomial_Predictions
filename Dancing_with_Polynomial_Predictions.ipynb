{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe856elK0rYW589+FnzrMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayed-Hossein-Hosseini/Dancing_with_Polynomial_Predictions/blob/master/Dancing_with_Polynomial_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dancing with Polynomial Predictions**"
      ],
      "metadata": {
        "id": "ON23E6jOj3qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "2k4-7PjhkKx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MFMQ6GgrjoDU"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Description**"
      ],
      "metadata": {
        "id": "Es8IK7CXkVWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_path = 'Polynomial_Functions.xlsx'  # Change the path if needed\n",
        "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "\n",
        "# Display general information about the dataset\n",
        "print(\"ðŸ”¹ Dataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values in each column\n",
        "print(\"\\nðŸ”¹ Missing Values Per Column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Show descriptive statistics\n",
        "print(\"\\nðŸ”¹ Descriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Count unique values in each column\n",
        "print(\"\\nðŸ”¹ Number of Unique Values Per Column:\")\n",
        "print(df.nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiVCh7TYkckA",
        "outputId": "84e48eed-fc2d-41d5-9201-f957dc421f8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   x           10000 non-null  float64\n",
            " 1   y           10000 non-null  float64\n",
            " 2   z           10000 non-null  float64\n",
            " 3   F(x, y, z)  10000 non-null  float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 312.6 KB\n",
            "None\n",
            "\n",
            "ðŸ”¹ Missing Values Per Column:\n",
            "x             0\n",
            "y             0\n",
            "z             0\n",
            "F(x, y, z)    0\n",
            "dtype: int64\n",
            "\n",
            "ðŸ”¹ Descriptive Statistics:\n",
            "                  x             y             z    F(x, y, z)\n",
            "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
            "mean      -0.116809      0.090598      0.001008     43.803057\n",
            "std        5.752603      5.785891      5.735475    587.941231\n",
            "min       -9.999767     -9.996845     -9.999038  -3191.680304\n",
            "25%       -5.073423     -4.921084     -4.925042   -225.322605\n",
            "50%       -0.149428      0.117936      0.041362     15.622764\n",
            "75%        4.800127      5.129584      4.893477    301.709432\n",
            "max        9.994353      9.998497      9.998020   3508.399526\n",
            "\n",
            "ðŸ”¹ Number of Unique Values Per Column:\n",
            "x             10000\n",
            "y             10000\n",
            "z             10000\n",
            "F(x, y, z)    10000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train/Test Split**"
      ],
      "metadata": {
        "id": "nFjcyGAF2WzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop('F(x, y, z)', axis=1)\n",
        "y = df['F(x, y, z)']\n",
        "\n",
        "# Split into training and test sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the sizes\n",
        "print(f\"Training set size: {X_train.shape[0]} rows\")\n",
        "print(f\"Test set size: {X_test.shape[0]} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQOELNok2n80",
        "outputId": "64c515b9-1232-4196-8ad4-c898e4ab384a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 8000 rows\n",
            "Test set size: 2000 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "tWgTmnBI14-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove Outliers**"
      ],
      "metadata": {
        "id": "OfAJ7e9el09S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_auto_xy_with_output(x, y):\n",
        "    \"\"\"\n",
        "    Automatically detect and remove outliers from the training data (x, y) using the IQR method.\n",
        "    Removes rows from both x and y simultaneously when an outlier is detected in either x or y.\n",
        "\n",
        "    Parameters:\n",
        "        x (pd.DataFrame): Input feature DataFrame (training data)\n",
        "        y (pd.Series): Input target Series (labels)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame, pd.Series: Cleaned feature DataFrame and target Series with outliers removed\n",
        "    \"\"\"\n",
        "    initial_shape = x.shape\n",
        "    print(f\"ðŸ”¹ Initial dataset size: {initial_shape[0]} rows, {initial_shape[1]} columns (x), {y.shape[0]} rows (y)\\n\")\n",
        "\n",
        "    # For numeric columns in x\n",
        "    numeric_cols_x = x.select_dtypes(include='number').columns\n",
        "    x_clean = x.copy()\n",
        "    y_clean = y.copy()\n",
        "\n",
        "    # Remove outliers from x\n",
        "    for col in numeric_cols_x:\n",
        "        Q1 = x[col].quantile(0.25)\n",
        "        Q3 = x[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        before = x_clean.shape[0]\n",
        "        mask = (x_clean[col] >= lower_bound) & (x_clean[col] <= upper_bound)\n",
        "\n",
        "        # Apply the same mask to both x and y\n",
        "        x_clean = x_clean[mask]\n",
        "        y_clean = y_clean[mask]\n",
        "\n",
        "        after = x_clean.shape[0]\n",
        "        removed = before - after\n",
        "\n",
        "        if removed > 0:\n",
        "            print(f\"ðŸŸ  Removed {removed} outliers from column '{col}' in x\")\n",
        "        else:\n",
        "            print(f\"âœ… No outliers detected in column '{col}' in x\")\n",
        "\n",
        "    # For the target variable y\n",
        "    Q1_y = y_clean.quantile(0.25)\n",
        "    Q3_y = y_clean.quantile(0.75)\n",
        "    IQR_y = Q3_y - Q1_y\n",
        "    lower_bound_y = Q1_y - 1.5 * IQR_y\n",
        "    upper_bound_y = Q3_y + 1.5 * IQR_y\n",
        "\n",
        "    before_y = y_clean.shape[0]\n",
        "    y_mask = (y_clean >= lower_bound_y) & (y_clean <= upper_bound_y)\n",
        "\n",
        "    # Apply the same mask to both x and y\n",
        "    x_clean = x_clean[y_mask]\n",
        "    y_clean = y_clean[y_mask]\n",
        "\n",
        "    after_y = x_clean.shape[0]\n",
        "    removed_y = before_y - after_y\n",
        "\n",
        "    if removed_y > 0:\n",
        "        print(f\"ðŸŸ  Removed {removed_y} outliers from target variable y\")\n",
        "    else:\n",
        "        print(f\"âœ… No outliers detected in target variable y\")\n",
        "\n",
        "    print(f\"\\nâœ… Final dataset size: {x_clean.shape[0]} rows (removed {initial_shape[0] - x_clean.shape[0]} total rows)\")\n",
        "    return x_clean, y_clean\n",
        "\n",
        "# Example usage:\n",
        "X_train_clean, y_train_clean = remove_outliers_auto_xy_with_output(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnyNSg5nl1S9",
        "outputId": "e78f9b55-c147-4198-918c-692b44d82202"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Initial dataset size: 8000 rows, 3 columns (x), 8000 rows (y)\n",
            "\n",
            "âœ… No outliers detected in column 'x' in x\n",
            "âœ… No outliers detected in column 'y' in x\n",
            "âœ… No outliers detected in column 'z' in x\n",
            "ðŸŸ  Removed 603 outliers from target variable y\n",
            "\n",
            "âœ… Final dataset size: 7397 rows (removed 603 total rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalize Data**"
      ],
      "metadata": {
        "id": "5YmR6zxoEftY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    This function normalizes the training and test features (X) and outputs (y).\n",
        "\n",
        "    Parameters:\n",
        "        X_train (numpy array): Training features\n",
        "        X_test (numpy array): Test features\n",
        "        y_train (numpy array): Training outputs\n",
        "        y_test (numpy array): Test outputs\n",
        "\n",
        "    Returns:\n",
        "        X_train_normalized (numpy array): Normalized training features\n",
        "        X_test_normalized (numpy array): Normalized test features\n",
        "        y_train_normalized (numpy array): Normalized training outputs\n",
        "        y_test_normalized (numpy array): Normalized test outputs\n",
        "        feature_scaler (dict): Feature normalization parameters (mean, std)\n",
        "        output_scaler (dict): Output normalization parameters (mean, std)\n",
        "    \"\"\"\n",
        "    # Step 1: Normalize features\n",
        "    feature_mean = np.mean(X_train, axis=0)  # Mean of each feature in X_train\n",
        "    feature_std = np.std(X_train, axis=0)    # Standard deviation of each feature in X_train\n",
        "    X_train_normalized = (X_train - feature_mean) / feature_std\n",
        "    X_test_normalized = (X_test - feature_mean) / feature_std\n",
        "\n",
        "    # Step 2: Normalize outputs\n",
        "    output_mean = np.mean(y_train)  # Mean of y_train\n",
        "    output_std = np.std(y_train)    # Standard deviation of y_train\n",
        "    y_train_normalized = (y_train - output_mean) / output_std\n",
        "    y_test_normalized = (y_test - output_mean) / output_std\n",
        "\n",
        "    # Store normalization parameters for later use (e.g., denormalization)\n",
        "    feature_scaler = {\"mean\": feature_mean, \"std\": feature_std}\n",
        "    output_scaler = {\"mean\": output_mean, \"std\": output_std}\n",
        "\n",
        "    return X_train_normalized, X_test_normalized, y_train_normalized, y_test_normalized, feature_scaler, output_scaler\n",
        "\n",
        "# Example usage\n",
        "# Assume you have the following datasets\n",
        "# X_train = np.array([\n",
        "#     [-2.5092, -2.52718, 4.59997],\n",
        "#     [9.01429, -3.34176, -6.30976],\n",
        "#     [4.63988, -6.47692, -3.06721],\n",
        "#     [1.97137, 2.14533, 3.26561],\n",
        "#     [-6.87963, -0.46752, -0.35821]\n",
        "# ])\n",
        "\n",
        "# X_test = np.array([\n",
        "#     [-6.88011, 7.31402, 4.77142],\n",
        "#     [-8.83833, -9.35781, 9.22416]\n",
        "# ])\n",
        "\n",
        "# y_train = np.array([100, 200, 300, 400, 500])\n",
        "# y_test = np.array([600, 700])\n",
        "\n",
        "# Normalize the data\n",
        "X_train_norm, X_test_norm, y_train_norm, y_test_norm, feature_scaler, output_scaler = normalize_data(X_train_clean, X_test, y_train_clean, y_test)\n",
        "\n",
        "# print(y_train_clean.head())\n",
        "# Display normalized data\n",
        "print(\"Normalized Training Features (X_train):\")\n",
        "print(X_train_norm.head())\n",
        "print(\"\\nNormalized Testing Features (X_test):\")\n",
        "print(X_test_norm.head())\n",
        "print(\"\\nNormalized Training Outputs (y_train):\")\n",
        "print(y_train_norm.head())\n",
        "print(\"\\nNormalized Testing Outputs (y_test):\")\n",
        "print(y_test_norm.head())\n",
        "\n",
        "# Denormalize outputs (example)\n",
        "def denormalize(data, scaler):\n",
        "    return data * scaler[\"std\"] + scaler[\"mean\"]\n",
        "\n",
        "# Example: Denormalize y_train_normalized\n",
        "y_train_denormalized = denormalize(y_train_norm, output_scaler)\n",
        "print(\"\\nDenormalized Training Outputs (y_train):\")\n",
        "print(y_train_denormalized.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHDX3OOLEf9g",
        "outputId": "25f6ac17-b7d9-4ebc-e5d1-e5f8fc11dd31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Training Features (X_train):\n",
            "             x         y         z\n",
            "9254  1.010234 -1.254771  1.617384\n",
            "1561 -0.915031 -0.877572 -1.162636\n",
            "1670 -0.396696 -0.584460 -0.077917\n",
            "6087 -1.026385  1.302232  1.098537\n",
            "5933  1.793400 -1.683188  0.390292\n",
            "\n",
            "Normalized Testing Features (X_test):\n",
            "             x         y         z\n",
            "6252 -0.552270 -1.431263  1.687950\n",
            "4684  1.027148  1.013973 -1.091141\n",
            "1731  0.480483 -1.035976  1.761235\n",
            "4742 -1.640797  1.072328 -1.331246\n",
            "4521  0.311811  1.552574 -0.517810\n",
            "\n",
            "Normalized Training Outputs (y_train):\n",
            "9254    0.312019\n",
            "1561   -1.838754\n",
            "1670   -0.154669\n",
            "6087    1.032377\n",
            "5933   -1.259422\n",
            "Name: F(x, y, z), dtype: float64\n",
            "\n",
            "Normalized Testing Outputs (y_test):\n",
            "6252   -1.631598\n",
            "4684    0.934388\n",
            "1731    0.044508\n",
            "4742   -0.995126\n",
            "4521    0.791898\n",
            "Name: F(x, y, z), dtype: float64\n",
            "\n",
            "Denormalized Training Outputs (y_train):\n",
            "9254    154.530442\n",
            "1561   -701.158409\n",
            "1670    -31.142075\n",
            "6087    441.126098\n",
            "5933   -470.670206\n",
            "Name: F(x, y, z), dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Engineering**"
      ],
      "metadata": {
        "id": "6KUU7Zjf37wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(x, y, z):\n",
        "    \"\"\"\n",
        "    This function takes x, y, z as inputs and returns the feature vector phi(x, y, z).\n",
        "    \"\"\"\n",
        "    # Compute all the required terms\n",
        "    phi = [\n",
        "        1,                      # Bias term (b)\n",
        "        x,                      # x^1\n",
        "        x**2,                   # x^2\n",
        "        x**3,                   # x^3\n",
        "        y,                      # y^1\n",
        "        y**2,                   # y^2\n",
        "        y**3,                   # y^3\n",
        "        z,                      # z^1\n",
        "        z**2,                   # z^2\n",
        "        z**3,                   # z^3\n",
        "        x * y,                  # xy\n",
        "        x**2 * y,               # x^2y\n",
        "        x * y**2,               # xy^2\n",
        "        x * z,                  # xz\n",
        "        x**2 * z,               # x^2z\n",
        "        x * z**2,               # xz^2\n",
        "        y * z,                  # yz\n",
        "        y**2 * z,               # y^2z\n",
        "        y * z**2,               # yz^2\n",
        "        x * y * z               # xyz\n",
        "    ]\n",
        "\n",
        "    return np.array(phi)\n",
        "\n",
        "# Example usage\n",
        "x, y, z = 2, 3, 4\n",
        "phi_vector = feature_engineering(x, y, z)\n",
        "print(\"Feature Vector:\", phi_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxOfDji4ADD",
        "outputId": "f0951a9e-51b3-4ddc-ad9b-6ac96df4d0a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Vector: [ 1  2  4  8  3  9 27  4 16 64  6 12 18  8 16 32 12 36 48 24]\n"
          ]
        }
      ]
    }
  ]
}